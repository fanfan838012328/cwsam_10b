"""
éªŒè¯å®Œæ•´æ¨¡å‹çš„å‚æ•°å†»ç»“
"""

import torch
import yaml
import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/mnt/fanfq/project/code/cwsam_10b')

import models


def test_full_model_freezing():
    """æµ‹è¯•å®Œæ•´æ¨¡å‹çš„å‚æ•°å†»ç»“"""
    print("æµ‹è¯•å®Œæ•´10Bæ¨¡å‹çš„å‚æ•°å†»ç»“...")
    
    # 1. åŠ è½½é…ç½®
    config_path = '/mnt/fanfq/project/code/cwsam_10b/configs/XinTong/XinTong_sam_vit_h_moe_3b.yaml'
    with open(config_path, 'r') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
    
    print(f"æ¨¡å‹é…ç½®: {config['model']['name']}")
    
    # 2. åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºæ¨¡å‹...")
    model = models.make(config['model'])
    
    # 3. ç»Ÿè®¡åˆå§‹å‚æ•°
    total_params_initial = sum(p.numel() for p in model.parameters())
    trainable_params_initial = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nåˆå§‹çŠ¶æ€:")
    print(f"  æ€»å‚æ•°: {total_params_initial:,} ({total_params_initial/1e9:.1f}B)")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params_initial:,}")
    print(f"  å†»ç»“å‚æ•°: {total_params_initial - trainable_params_initial:,}")
    
    # 4. åŠ è½½checkpoint
    checkpoint_path = config.get('sam_checkpoint')
    if not os.path.exists(checkpoint_path):
        print(f"è­¦å‘Š: checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return False
    
    print(f"\nåŠ è½½checkpoint...")
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # åº”ç”¨åŸºç¡€æƒé‡
    model_dict = model.state_dict()
    filtered_dict = {k: v for k, v in checkpoint.items() 
                    if k in model_dict and model_dict[k].shape == v.shape}
    model.load_state_dict(filtered_dict, strict=False)
    print(f"åŠ è½½äº† {len(filtered_dict)} ä¸ªåŒ¹é…çš„æƒé‡å‚æ•°")
    
    # 5. åˆå§‹åŒ–MoEæƒé‡ï¼ˆè¿™é‡Œä¼šå†»ç»“å‚æ•°ï¼‰
    print(f"\nåˆå§‹åŒ–MoEæƒé‡...")
    moe_layer_count = 0
    for name, module in model.named_modules():
        if hasattr(module, 'load_1_5b_expert_weights'):
            print(f"  æ­£åœ¨åˆå§‹åŒ–: {name}")
            module.load_1_5b_expert_weights(checkpoint)
            moe_layer_count += 1
            
            # åªæ˜¾ç¤ºå‰å‡ å±‚çš„è¯¦ç»†ä¿¡æ¯
            if moe_layer_count <= 3:
                layer_total = sum(p.numel() for p in module.parameters())
                layer_trainable = sum(p.numel() for p in module.parameters() if p.requires_grad)
                layer_frozen = layer_total - layer_trainable
                print(f"    å±‚å‚æ•°: æ€»={layer_total:,}, å¯è®­ç»ƒ={layer_trainable:,}, å†»ç»“={layer_frozen:,}")
    
    print(f"æ€»å…±åˆå§‹åŒ–äº† {moe_layer_count} ä¸ªMoEå±‚")
    
    # 6. ç»Ÿè®¡æœ€ç»ˆå‚æ•°çŠ¶æ€
    total_params_final = sum(p.numel() for p in model.parameters())
    trainable_params_final = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params_final = total_params_final - trainable_params_final
    
    print(f"\næœ€ç»ˆçŠ¶æ€:")
    print(f"  æ€»å‚æ•°: {total_params_final:,} ({total_params_final/1e9:.1f}B)")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params_final:,} ({trainable_params_final/1e9:.1f}B)")
    print(f"  å†»ç»“å‚æ•°: {frozen_params_final:,} ({frozen_params_final/1e9:.1f}B)")
    
    # 7. åˆ†æå†»ç»“æ•ˆæœ
    frozen_change = frozen_params_final - (total_params_initial - trainable_params_initial)
    trainable_ratio = trainable_params_final / total_params_final * 100
    frozen_ratio = frozen_params_final / total_params_final * 100
    
    print(f"\nå†»ç»“åˆ†æ:")
    print(f"  æ–°å¢å†»ç»“å‚æ•°: {frozen_change:,}")
    print(f"  å¯è®­ç»ƒæ¯”ä¾‹: {trainable_ratio:.1f}%")
    print(f"  å†»ç»“æ¯”ä¾‹: {frozen_ratio:.1f}%")
    
    # 8. éªŒè¯ç»“æœ
    expected_frozen_ratio = 30  # é¢„æœŸå¤§çº¦30%çš„å‚æ•°è¢«å†»ç»“
    
    if frozen_change > 1000000 and frozen_ratio > expected_frozen_ratio:
        print(f"\nâœ“ å‚æ•°å†»ç»“æˆåŠŸï¼")
        print(f"  âœ“ å†»ç»“äº† {frozen_change:,} ä¸ª1.5Bä¸“å®¶å‚æ•°")
        print(f"  âœ“ å†»ç»“æ¯”ä¾‹ {frozen_ratio:.1f}% ç¬¦åˆé¢„æœŸ")
        print(f"  âœ“ å¯è®­ç»ƒå‚æ•° {trainable_params_final/1e9:.1f}B åˆç†")
        return True
    else:
        print(f"\nâœ— å‚æ•°å†»ç»“å¯èƒ½æœ‰é—®é¢˜")
        print(f"  å†»ç»“å˜åŒ–: {frozen_change:,} (é¢„æœŸ > 1,000,000)")
        print(f"  å†»ç»“æ¯”ä¾‹: {frozen_ratio:.1f}% (é¢„æœŸ > {expected_frozen_ratio}%)")
        return False


if __name__ == "__main__":
    print("=" * 70)
    print("å®Œæ•´10Bæ¨¡å‹å‚æ•°å†»ç»“éªŒè¯")
    print("=" * 70)
    
    success = test_full_model_freezing()
    
    print("\n" + "=" * 70)
    if success:
        print("ğŸ‰ å‚æ•°å†»ç»“éªŒè¯æˆåŠŸï¼")
        print("âœ“ 1.5Bä¸“å®¶æƒé‡æ­£ç¡®å†»ç»“")
        print("âœ“ æ–°ä¸“å®¶æƒé‡å¯ä»¥è®­ç»ƒ")
        print("âœ“ å‚æ•°åˆ†é…åˆç†")
        print("âœ“ æ¨¡å‹å·²å‡†å¤‡å¥½è®­ç»ƒ")
    else:
        print("âŒ å‚æ•°å†»ç»“éªŒè¯å¤±è´¥")
        print("éœ€è¦æ£€æŸ¥å†»ç»“é€»è¾‘")
    print("=" * 70)